{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29e9aa04",
   "metadata": {},
   "source": [
    "# PyTorch Tutorial 09 - Dataset and DataLoader - Batch Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8820085e",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=PXOzkkB5eH0&list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4&index=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dc4850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3e186f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45832b42",
   "metadata": {},
   "source": [
    "## Dataset child-class creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8629d079",
   "metadata": {},
   "source": [
    "https://www.educba.com/dataset-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c10dbaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WineDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        # data loading\n",
    "        xy = np.loadtxt('wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
    "        self.x = torch.from_numpy(xy[:, 1:])  # the first column is skipped, because it is the target\n",
    "        self.y = torch.from_numpy(xy[:, [0]])  # n_samples, 1\n",
    "        self.n_samples = xy.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426f4e16",
   "metadata": {},
   "source": [
    "#### Dataset demonstration; let's take a look into the first element of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "899b53bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = WineDataset()\n",
    "# first_data = dataset[0]\n",
    "# features, labels = first_data\n",
    "# print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd21a3d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c258a191",
   "metadata": {},
   "source": [
    "## DataLoader class creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31f8c80",
   "metadata": {},
   "source": [
    "The data loading process is done in a parallel mode where collecting the batch details is carried out automatically with the help of PyTorch, which is called PyTorch DataLoader. This helps in doing the data loading process faster than ever with less memory in place. DataLoader has both dataset and sampler within itself so that an iterable can be formed in the dataset. We can do single loading or multi-process loading based on the amount of data and the speed required for the process and can be combined with map-style or iterable-style of the datasets where the loading order can be customized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f161d2",
   "metadata": {},
   "source": [
    "https://www.educba.com/pytorch-dataloader/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d8ebce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x2ae6caf0340>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = WineDataset()\n",
    "dataloader = DataLoader(dataset=dataset, \n",
    "                        batch_size=4, \n",
    "                        shuffle=True, \n",
    "                        num_workers=0)  # 'num_workers' was set to 0 to prevent errors with 'dataloader';\n",
    "                                        # probably, 'num_workers' can be different from 0 in CUDA PyTorch version;\n",
    "                                        # there's also an opinion that it's Windows problem with multiprocessing \n",
    "dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dee44ef",
   "metadata": {},
   "source": [
    "#### DataLoader demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7fd96e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataiter = iter(dataloader)\n",
    "# data = next(dataiter)\n",
    "# features, labels = data\n",
    "\n",
    "# features, labels  # 4 elements in a batch as was specified 'batch_size=4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c50025be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 45)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training loop\n",
    "num_epochs = 2\n",
    "total_samples = len(dataset)\n",
    "n_iterations = math.ceil(total_samples/4)\n",
    "\n",
    "total_samples, n_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33de6fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/2, step 5/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 10/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 15/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 20/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 25/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 30/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 35/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 40/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 45/45, inputs torch.Size([2, 13])\n",
      "epoch 2/2, step 5/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 10/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 15/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 20/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 25/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 30/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 35/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 40/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 45/45, inputs torch.Size([2, 13])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        # forward, backward, update\n",
    "        if (i+1) % 5 == 0:\n",
    "            print(f'epoch {epoch+1}/{num_epochs}, step {i+1}/{n_iterations}, inputs {inputs.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d5fb15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0387d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
